#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Multi-Source Automated Price Management System
Handles multiple price sources in parallel with automatic classification
"""
import sys
import os
import json
import time
import hashlib
from datetime import datetime
from typing import List, Dict, Optional, Tuple
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed
from multiprocessing import cpu_count
import psycopg2
from psycopg2.extras import RealDictCursor

sys.stdout.reconfigure(encoding='utf-8')

# ========================================
# Configuration
# ========================================

DB_CONFIG = {
    'dbname': 'gogobe',
    'user': 'postgres',
    'password': '9152245-Gl!',
    'host': 'localhost',
    'port': '5432'
}

# How many parallel processes/threads
MAX_WORKERS = min(cpu_count(), 8)  # Don't overload the system
CHUNK_SIZE = 1000  # Products per batch

# ========================================
# Multi-Language Category Keywords
# ========================================

CATEGORY_KEYWORDS_MULTILANG = {
    'Dairy': {
        'he': ['×—×œ×‘', '×’×‘×™× ×”', '×™×•×’×•×¨×˜', '×§×•×˜×’', '×œ×‘× ×”', '×©×ž× ×ª', '×—×ž××”', '×ž×¨×’×¨×™× ×”', '×‘×™×¦'],
        'en': ['milk', 'cheese', 'yogurt', 'cottage', 'cream', 'butter', 'egg', 'dairy'],
        'ar': ['Ø­Ù„ÙŠØ¨', 'Ø¬Ø¨Ù†', 'Ø²Ø¨Ø§Ø¯ÙŠ', 'Ù‚Ø´Ø¯Ø©', 'Ø²Ø¨Ø¯Ø©', 'Ø¨ÙŠØ¶'],
        'ru': ['Ð¼Ð¾Ð»Ð¾ÐºÐ¾', 'ÑÑ‹Ñ€', 'Ð¹Ð¾Ð³ÑƒÑ€Ñ‚', 'Ñ‚Ð²Ð¾Ñ€Ð¾Ð³', 'ÑÐ»Ð¸Ð²ÐºÐ¸', 'Ð¼Ð°ÑÐ»Ð¾', 'ÑÐ¹Ñ†Ð¾'],
        'brands': ['×ª× ×•×‘×”', 'tnuva', '×©×˜×¨××•×¡', 'strauss', '×™×•×˜×‘×ª×”', '×“× ×•× ×”', 'danone']
    },
    
    'Bakery': {
        'he': ['×œ×—×', '×—×œ×”', '×¤×™×ª×”', '×‘×’×˜', '×ž××¤×”', '×¢×•×’×”', '×¢×•×’×™', '×‘×™×¡×§×•×•×™×˜', '×§×ž×—'],
        'en': ['bread', 'baguette', 'cake', 'cookie', 'biscuit', 'bagel', 'flour', 'pastry'],
        'ar': ['Ø®Ø¨Ø²', 'ÙƒØ¹Ùƒ', 'Ø¨Ø³ÙƒÙˆÙŠØª', 'Ø¯Ù‚ÙŠÙ‚'],
        'ru': ['Ñ…Ð»ÐµÐ±', 'Ð±ÑƒÐ»ÐºÐ°', 'Ð¿ÐµÑ‡ÐµÐ½ÑŒÐµ', 'Ñ‚Ð¾Ñ€Ñ‚', 'Ð¼ÑƒÐºÐ°']
    },
    
    'Beverages': {
        'he': ['×ž×™×¥', '×§×•×œ×”', '×¤×¤×¡×™', '×ž×©×§×”', '×©×ª×™×”', '×‘×™×¨×”', '×™×™×Ÿ', '×ž×™×', '×§×¤×”', '×ª×”', '×©×•×§×•'],
        'en': ['juice', 'cola', 'pepsi', 'drink', 'beverage', 'beer', 'wine', 'water', 'coffee', 'tea'],
        'ar': ['Ø¹ØµÙŠØ±', 'ÙƒÙˆÙ„Ø§', 'Ù…Ø´Ø±ÙˆØ¨', 'Ø¨ÙŠØ±Ø©', 'Ù†Ø¨ÙŠØ°', 'Ù…Ø§Ø¡', 'Ù‚Ù‡ÙˆØ©', 'Ø´Ø§ÙŠ'],
        'ru': ['ÑÐ¾Ðº', 'ÐºÐ¾Ð»Ð°', 'Ð½Ð°Ð¿Ð¸Ñ‚Ð¾Ðº', 'Ð¿Ð¸Ð²Ð¾', 'Ð²Ð¸Ð½Ð¾', 'Ð²Ð¾Ð´Ð°', 'ÐºÐ¾Ñ„Ðµ', 'Ñ‡Ð°Ð¹'],
        'brands': ['×§×•×§×” ×§×•×œ×”', 'coca cola', '×¡×¤×¨×™×™×˜', 'sprite', '×¤×¨×™×’×ª', 'prigat', '×˜×¨×•×¤×™×§× ×”']
    },
    
    'Meat': {
        'he': ['×‘×©×¨', '×¢×•×£', '×›×‘×©', '×”×•×“×•', '× ×§× ×™×§', '×”×ž×‘×•×¨×’×¨', '×§×‘×‘', '×©× ×™×¦×œ', '×“×’', '×˜×•× ×”', '×¡×œ×ž×•×Ÿ'],
        'en': ['meat', 'chicken', 'beef', 'turkey', 'sausage', 'burger', 'schnitzel', 'fish', 'tuna', 'salmon'],
        'ar': ['Ù„Ø­Ù…', 'Ø¯Ø¬Ø§Ø¬', 'Ù„Ø­Ù… Ø¨Ù‚Ø±', 'Ø³Ù…Ùƒ', 'ØªÙˆÙ†Ø©'],
        'ru': ['Ð¼ÑÑÐ¾', 'ÐºÑƒÑ€Ð¸Ñ†Ð°', 'Ð³Ð¾Ð²ÑÐ´Ð¸Ð½Ð°', 'Ñ€Ñ‹Ð±Ð°', 'Ñ‚ÑƒÐ½ÐµÑ†'],
        'brands': ['×¢×•×£ ×˜×¨×™', '×–×•×’×œ×•×‘×§', '×™×›×™×Ÿ', '×˜×™×‘ ×˜×¢×']
    },
    
    'Vegetables': {
        'he': ['×¢×’×‘× ×™', '×ž×œ×¤×¤×•×Ÿ', '×—×¡×”', '×’×–×¨', '×‘×¦×œ', '×©×•×', '×ª×¤×•×— ××“×ž×”', '×›×¨×•×‘', '×¤×œ×¤×œ', '×—×¦×™×œ', '×™×¨×§', '×¡×œ×˜'],
        'en': ['tomato', 'cucumber', 'lettuce', 'carrot', 'onion', 'garlic', 'potato', 'cabbage', 'pepper', 'eggplant', 'vegetable', 'salad'],
        'ar': ['Ø·Ù…Ø§Ø·Ù…', 'Ø®ÙŠØ§Ø±', 'Ø®Ø³', 'Ø¬Ø²Ø±', 'Ø¨ØµÙ„', 'Ø«ÙˆÙ…', 'Ø¨Ø·Ø§Ø·Ø§', 'ÙÙ„ÙÙ„', 'Ø®Ø¶Ø§Ø±'],
        'ru': ['Ð¿Ð¾Ð¼Ð¸Ð´Ð¾Ñ€', 'Ð¾Ð³ÑƒÑ€ÐµÑ†', 'ÑÐ°Ð»Ð°Ñ‚', 'Ð¼Ð¾Ñ€ÐºÐ¾Ð²ÑŒ', 'Ð»ÑƒÐº', 'Ñ‡ÐµÑÐ½Ð¾Ðº', 'ÐºÐ°Ñ€Ñ‚Ð¾Ñ„ÐµÐ»ÑŒ', 'Ð¾Ð²Ð¾Ñ‰']
    },
    
    'Fruits': {
        'he': ['×ª×¤×•×—', '×‘× × ×”', '×ª×¤×•×–', '××‘×˜×™×—', '×ž×œ×•×Ÿ', '×¢× ×‘', '××’×¡', '×× × ×¡', '×ª×•×ª', '×¤×¨×™', '×œ×™×ž×•×Ÿ', '××©×›×•×œ×™×ª'],
        'en': ['apple', 'banana', 'orange', 'watermelon', 'melon', 'grape', 'pear', 'pineapple', 'strawberry', 'fruit', 'lemon'],
        'ar': ['ØªÙØ§Ø­', 'Ù…ÙˆØ²', 'Ø¨Ø±ØªÙ‚Ø§Ù„', 'Ø¨Ø·ÙŠØ®', 'Ø¹Ù†Ø¨', 'ÙØ±Ø§ÙˆÙ„Ø©', 'ÙØ§ÙƒÙ‡Ø©'],
        'ru': ['ÑÐ±Ð»Ð¾ÐºÐ¾', 'Ð±Ð°Ð½Ð°Ð½', 'Ð°Ð¿ÐµÐ»ÑŒÑÐ¸Ð½', 'Ð°Ñ€Ð±ÑƒÐ·', 'Ð²Ð¸Ð½Ð¾Ð³Ñ€Ð°Ð´', 'Ð³Ñ€ÑƒÑˆÐ°', 'Ñ„Ñ€ÑƒÐºÑ‚']
    },
    
    'Snacks': {
        'he': ['×—×˜×™×£', '×‘×ž×‘×”', '×‘×™×¡×œ×™', '×“×•×¨×™×˜×•×¡', '×¦\'×™×¤×¡', '×¤×•×¤×§×•×¨×Ÿ', '×©×•×§×•×œ×“', '×ž×ž×ª×§', '×¡×•×›×¨×™', '×’×¨×¢×™×Ÿ', '××’×•×–', '×•×•×¤×œ'],
        'en': ['snack', 'chips', 'doritos', 'popcorn', 'chocolate', 'candy', 'nut', 'seed', 'wafer'],
        'ar': ['ÙˆØ¬Ø¨Ø© Ø®ÙÙŠÙØ©', 'Ø´ÙˆÙƒÙˆÙ„Ø§ØªØ©', 'Ø­Ù„ÙˆÙ‰', 'Ù…ÙƒØ³Ø±Ø§Øª'],
        'ru': ['Ð·Ð°ÐºÑƒÑÐºÐ°', 'Ñ‡Ð¸Ð¿ÑÑ‹', 'ÑˆÐ¾ÐºÐ¾Ð»Ð°Ð´', 'ÐºÐ¾Ð½Ñ„ÐµÑ‚Ñ‹', 'Ð¾Ñ€ÐµÑ…Ð¸'],
        'brands': ['×‘×ž×‘×”', 'bamba', '×‘×™×¡×œ×™', 'bissli', 'elite', '××œ×™×˜']
    },
    
    'Household': {
        'he': ['×¡×‘×•×Ÿ', '× ×™×§×•×™', '× ×™×™×¨ ×˜×•××œ×˜', '×ž×’×‘×ª', '×©×§×™×ª', '××§×•× ×•×ž×™×§×”', '×›×œ×™×', '×©×ž×¤×•', '×ž×¨×›×š'],
        'en': ['soap', 'detergent', 'toilet paper', 'towel', 'bag', 'sponge', 'cleaning', 'dishes', 'shampoo'],
        'ar': ['ØµØ§Ø¨ÙˆÙ†', 'Ù…Ù†Ø¸Ù', 'ÙˆØ±Ù‚ ØªÙˆØ§Ù„ÙŠØª', 'ÙƒÙŠØ³', 'ØªÙ†Ø¸ÙŠÙ'],
        'ru': ['Ð¼Ñ‹Ð»Ð¾', 'Ð¼Ð¾ÑŽÑ‰ÐµÐµ ÑÑ€ÐµÐ´ÑÑ‚Ð²Ð¾', 'Ñ‚ÑƒÐ°Ð»ÐµÑ‚Ð½Ð°Ñ Ð±ÑƒÐ¼Ð°Ð³Ð°', 'Ð¿Ð¾Ð»Ð¾Ñ‚ÐµÐ½Ñ†Ðµ', 'Ð¿Ð°ÐºÐµÑ‚']
    },
    
    'Personal Care': {
        'he': ['×ž×©×—×ª ×©×™× ×™×™×', '×ž×‘×¨×©×ª ×©×™× ×™×™×', '×“××•×“×•×¨× ×˜', '×§×¨×', '×¡×‘×•×Ÿ ×’×•×£', '×˜×™×¤×•×—', '×©×™×¢×¨', '×¢×•×¨', '×•×™×˜×ž×™×Ÿ', '×ª×•×¡×£'],
        'en': ['toothpaste', 'toothbrush', 'deodorant', 'cream', 'body wash', 'care', 'hair', 'skin', 'vitamin'],
        'ar': ['Ù…Ø¹Ø¬ÙˆÙ† Ø£Ø³Ù†Ø§Ù†', 'ÙØ±Ø´Ø§Ø© Ø£Ø³Ù†Ø§Ù†', 'Ù…Ø²ÙŠÙ„ Ø¹Ø±Ù‚', 'ÙƒØ±ÙŠÙ…', 'Ø¹Ù†Ø§ÙŠØ©'],
        'ru': ['Ð·ÑƒÐ±Ð½Ð°Ñ Ð¿Ð°ÑÑ‚Ð°', 'Ð·ÑƒÐ±Ð½Ð°Ñ Ñ‰ÐµÑ‚ÐºÐ°', 'Ð´ÐµÐ·Ð¾Ð´Ð¾Ñ€Ð°Ð½Ñ‚', 'ÐºÑ€ÐµÐ¼', 'ÑƒÑ…Ð¾Ð´']
    },
    
    'Frozen Foods': {
        'he': ['×§×¤×•×', '×’×œ×™×“×”'],
        'en': ['frozen', 'ice cream'],
        'ar': ['Ù…Ø¬Ù…Ø¯', 'Ø¢ÙŠØ³ ÙƒØ±ÙŠÙ…'],
        'ru': ['Ð·Ð°Ð¼Ð¾Ñ€Ð¾Ð¶ÐµÐ½Ð½Ñ‹Ð¹', 'Ð¼Ð¾Ñ€Ð¾Ð¶ÐµÐ½Ð¾Ðµ']
    },
    
    'Canned Foods': {
        'he': ['×©×™×ž×•×¨', '×§×•×¤×¡×”', '×ž×œ×¤×¤×•×Ÿ ×—×ž×•×¥'],
        'en': ['canned', 'can', 'pickle', 'preserved'],
        'ar': ['Ù…Ø¹Ù„Ø¨', 'Ù…Ø­ÙÙˆØ¸'],
        'ru': ['ÐºÐ¾Ð½ÑÐµÑ€Ð²Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹', 'ÐºÐ¾Ð½ÑÐµÑ€Ð²Ñ‹']
    },
    
    'Spices': {
        'he': ['×ª×‘×œ×™×Ÿ', '×¤×œ×¤×œ ×©×—×•×¨', '×›×ž×•×Ÿ', '×ž×œ×—', '××•×¨×’× ×•', '×‘×–×™×œ×™×§×•×', '×›×•×¨×›×•×'],
        'en': ['spice', 'pepper', 'cumin', 'salt', 'oregano', 'basil', 'turmeric'],
        'ar': ['ØªÙˆØ§Ø¨Ù„', 'ÙÙ„ÙÙ„', 'Ù…Ù„Ø­', 'ÙƒÙ…ÙˆÙ†'],
        'ru': ['ÑÐ¿ÐµÑ†Ð¸Ñ', 'Ð¿ÐµÑ€ÐµÑ†', 'ÑÐ¾Ð»ÑŒ', 'Ñ‚Ð¼Ð¸Ð½']
    },
    
    'Pasta & Rice': {
        'he': ['×¤×¡×˜×”', '×¡×¤×’×˜×™', '××•×¨×–', '×§×•×¡×§×•×¡', '× ×•×“×œ×¡'],
        'en': ['pasta', 'spaghetti', 'rice', 'couscous', 'noodles'],
        'ar': ['Ù…Ø¹ÙƒØ±ÙˆÙ†Ø©', 'Ø£Ø±Ø²', 'ÙƒØ³ÙƒØ³'],
        'ru': ['Ð¿Ð°ÑÑ‚Ð°', 'ÑÐ¿Ð°Ð³ÐµÑ‚Ñ‚Ð¸', 'Ñ€Ð¸Ñ', 'Ð»Ð°Ð¿ÑˆÐ°']
    },
    
    'Oils & Sauces': {
        'he': ['×©×ž×Ÿ', '×–×™×ª', '×¨×˜×‘', '×§×˜×©×•×¤', '×ž×™×•× ×–', '×—×¨×“×œ', '×¡×™×œ××Ÿ', '×“×‘×©'],
        'en': ['oil', 'olive', 'sauce', 'ketchup', 'mayo', 'mustard', 'honey'],
        'ar': ['Ø²ÙŠØª', 'Ø²ÙŠØªÙˆÙ†', 'ØµÙ„ØµØ©', 'ÙƒØ§ØªØ´Ø¨', 'Ù…Ø§ÙŠÙˆÙ†ÙŠØ²', 'Ø¹Ø³Ù„'],
        'ru': ['Ð¼Ð°ÑÐ»Ð¾', 'Ð¾Ð»Ð¸Ð²ÐºÐ°', 'ÑÐ¾ÑƒÑ', 'ÐºÐµÑ‚Ñ‡ÑƒÐ¿', 'Ð¼Ð°Ð¹Ð¾Ð½ÐµÐ·', 'Ð¼Ñ‘Ð´']
    },
    
    'Baby Products': {
        'he': ['×ª×™× ×•×§', '×—×™×ª×•×œ', '×ž×•×¦×¥', '×ª×¨×›×•×‘×ª'],
        'en': ['baby', 'diaper', 'pacifier', 'formula'],
        'ar': ['Ø·ÙÙ„', 'Ø­ÙØ§Ø¶', 'Ù„Ù‡Ø§ÙŠØ©'],
        'ru': ['Ñ€ÐµÐ±ÐµÐ½Ð¾Ðº', 'Ð¿Ð¾Ð´Ð³ÑƒÐ·Ð½Ð¸Ðº', 'ÑÐ¾ÑÐºÐ°', 'ÑÐ¼ÐµÑÑŒ']
    },
    
    'Pet Food': {
        'he': ['×›×œ×‘', '×—×ª×•×œ', '×—×™×™×ª ×ž×—×ž×“'],
        'en': ['dog', 'cat', 'pet'],
        'ar': ['ÙƒÙ„Ø¨', 'Ù‚Ø·Ø©', 'Ø­ÙŠÙˆØ§Ù† Ø£Ù„ÙŠÙ'],
        'ru': ['ÑÐ¾Ð±Ð°ÐºÐ°', 'ÐºÐ¾ÑˆÐºÐ°', 'Ð¿Ð¸Ñ‚Ð¾Ð¼ÐµÑ†']
    },
}


def normalize_text(text: str) -> str:
    """Normalize text for multi-language matching"""
    if not text:
        return ""
    # Convert to lowercase
    text = text.lower()
    # Remove extra spaces
    text = ' '.join(text.split())
    return text


def classify_product_multilang(product_name: str, description: str = "") -> Tuple[Optional[str], int, List[str]]:
    """
    Classify a product based on multi-language keywords
    Returns: (category_name, confidence_score, matched_keywords)
    """
    full_text = normalize_text(f"{product_name} {description}")
    
    category_scores = {}
    
    for category, languages in CATEGORY_KEYWORDS_MULTILANG.items():
        score = 0
        matched_keywords = []
        
        # Check all languages
        for lang, keywords in languages.items():
            for keyword in keywords:
                keyword_lower = keyword.lower()
                # Exact word match (higher score)
                if f" {keyword_lower} " in f" {full_text} ":
                    score += 10
                    matched_keywords.append(f"{keyword} [{lang}]")
                # Partial match (lower score)
                elif keyword_lower in full_text:
                    score += 5
                    matched_keywords.append(f"{keyword} [{lang}]")
        
        if score > 0:
            category_scores[category] = {
                'score': score,
                'keywords': matched_keywords
            }
    
    if category_scores:
        best_category = max(category_scores.items(), key=lambda x: x[1]['score'])
        return best_category[0], best_category[1]['score'], best_category[1]['keywords']
    
    return None, 0, []


def process_batch(batch_data: Dict) -> Dict:
    """
    Process a batch of products for classification
    This runs in a separate process for parallel processing
    """
    products = batch_data['products']
    vertical_id = batch_data['vertical_id']
    
    # Create new DB connection for this process
    conn = psycopg2.connect(**DB_CONFIG)
    cur = conn.cursor(cursor_factory=RealDictCursor)
    
    stats = {
        'processed': 0,
        'classified': 0,
        'by_category': {}
    }
    
    try:
        for product in products:
            category_name, score, keywords = classify_product_multilang(
                product['name'],
                product.get('description', '')
            )
            
            if category_name and score >= 5:
                # Get or create category
                cur.execute("""
                    SELECT id FROM categories 
                    WHERE name = %s AND vertical_id = %s
                """, (category_name, vertical_id))
                
                result = cur.fetchone()
                if result:
                    category_id = result['id']
                else:
                    # Create category
                    slug = category_name.lower().replace(' ', '-').replace('&', 'and')
                    try:
                        cur.execute("""
                            INSERT INTO categories (name, slug, vertical_id)
                            VALUES (%s, %s, %s)
                            RETURNING id
                        """, (category_name, slug, vertical_id))
                        category_id = cur.fetchone()['id']
                    except psycopg2.errors.UniqueViolation:
                        conn.rollback()
                        cur.execute("""
                            SELECT id FROM categories 
                            WHERE slug = %s AND vertical_id = %s
                        """, (slug, vertical_id))
                        category_id = cur.fetchone()['id']
                
                # Update product
                cur.execute("""
                    UPDATE products 
                    SET category_id = %s 
                    WHERE id = %s
                """, (category_id, product['id']))
                
                stats['classified'] += 1
                stats['by_category'][category_name] = stats['by_category'].get(category_name, 0) + 1
            
            stats['processed'] += 1
        
        conn.commit()
        
    except Exception as e:
        conn.rollback()
        stats['error'] = str(e)
    finally:
        conn.close()
    
    return stats


def classify_all_parallel(vertical_slug: str = 'supermarket', max_workers: int = MAX_WORKERS):
    """
    Classify all unclassified products using parallel processing
    """
    conn = psycopg2.connect(**DB_CONFIG)
    cur = conn.cursor(cursor_factory=RealDictCursor)
    
    try:
        # Get vertical ID
        cur.execute("SELECT id FROM verticals WHERE slug = %s", (vertical_slug,))
        result = cur.fetchone()
        if not result:
            print(f"[ERROR] Vertical '{vertical_slug}' not found!")
            return
        
        vertical_id = result['id']
        
        # Get unclassified products
        cur.execute("""
            SELECT id, name, description
            FROM products
            WHERE category_id IS NULL 
                AND vertical_id = %s
                AND is_active = true
            ORDER BY id
        """, (vertical_id,))
        
        products = cur.fetchall()
        total_products = len(products)
        
        if total_products == 0:
            print("[INFO] No unclassified products found!")
            return
        
        print(f"\n{'='*70}")
        print(f"ðŸš€ Parallel Classification - {max_workers} Workers")
        print(f"{'='*70}")
        print(f"Total products: {total_products:,}")
        print(f"Chunk size: {CHUNK_SIZE}")
        print(f"Estimated batches: {(total_products + CHUNK_SIZE - 1) // CHUNK_SIZE}")
        print(f"{'='*70}\n")
        
        # Split into batches
        batches = []
        for i in range(0, total_products, CHUNK_SIZE):
            batch = {
                'products': products[i:i + CHUNK_SIZE],
                'vertical_id': vertical_id
            }
            batches.append(batch)
        
        # Process in parallel
        start_time = time.time()
        total_stats = {
            'processed': 0,
            'classified': 0,
            'by_category': {}
        }
        
        with ProcessPoolExecutor(max_workers=max_workers) as executor:
            # Submit all batches
            futures = {executor.submit(process_batch, batch): i for i, batch in enumerate(batches)}
            
            # Collect results as they complete
            for future in as_completed(futures):
                batch_num = futures[future]
                try:
                    stats = future.result()
                    
                    total_stats['processed'] += stats['processed']
                    total_stats['classified'] += stats['classified']
                    
                    for cat, count in stats.get('by_category', {}).items():
                        total_stats['by_category'][cat] = total_stats['by_category'].get(cat, 0) + count
                    
                    # Progress
                    progress = (total_stats['processed'] / total_products) * 100
                    print(f"[{progress:5.1f}%] Batch {batch_num+1}/{len(batches)} complete - "
                          f"Classified: {stats['classified']}/{stats['processed']}")
                    
                except Exception as e:
                    print(f"[ERROR] Batch {batch_num} failed: {e}")
        
        elapsed_time = time.time() - start_time
        
        # Final statistics
        print(f"\n{'='*70}")
        print("Classification Complete!")
        print(f"{'='*70}")
        print(f"Time elapsed: {elapsed_time:.1f}s ({total_products/elapsed_time:.0f} products/sec)")
        print(f"Processed: {total_stats['processed']:,}")
        print(f"Classified: {total_stats['classified']:,} ({total_stats['classified']/total_stats['processed']*100:.1f}%)")
        print(f"\nBy Category:")
        for cat, count in sorted(total_stats['by_category'].items(), key=lambda x: x[1], reverse=True):
            print(f"  {cat:25} {count:6,} products")
        print(f"{'='*70}\n")
        
    finally:
        conn.close()


if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='Parallel multi-language product classifier')
    parser.add_argument('--workers', type=int, default=MAX_WORKERS, help=f'Number of parallel workers (default: {MAX_WORKERS})')
    parser.add_argument('--vertical', type=str, default='supermarket', help='Vertical slug (default: supermarket)')
    parser.add_argument('--test', type=str, help='Test classification for a product name')
    
    args = parser.parse_args()
    
    if args.test:
        # Test mode
        category, score, keywords = classify_product_multilang(args.test)
        print(f"\nProduct: {args.test}")
        print(f"Category: {category}")
        print(f"Score: {score}")
        print(f"Keywords: {', '.join(keywords[:5])}")
    else:
        # Parallel classification
        classify_all_parallel(vertical_slug=args.vertical, max_workers=args.workers)


