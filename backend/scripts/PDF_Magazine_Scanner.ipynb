{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ü¶∑ Gogobe - PDF Magazine Scanner\n",
        "\n",
        "Extract dental products from PDF magazines automatically!\n",
        "\n",
        "## üìã What this does:\n",
        "1. Upload PDF magazine\n",
        "2. Extract text\n",
        "3. Find products & prices\n",
        "4. Export to CSV/SQL\n",
        "5. Load into Gogobe database\n",
        "\n",
        "## üöÄ Run in Google Colab:\n",
        "1. Go to: https://colab.research.google.com\n",
        "2. File ‚Üí Upload notebook\n",
        "3. Upload this file\n",
        "4. Run cells!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install -q PyPDF2 pdfplumber pandas openpyxl\n",
        "print(\"‚úÖ Libraries installed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Upload PDF file\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "print(\"üì§ Upload your PDF magazine:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the uploaded file\n",
        "pdf_filename = list(uploaded.keys())[0]\n",
        "print(f\"\\n‚úÖ Uploaded: {pdf_filename}\")\n",
        "print(f\"   Size: {len(uploaded[pdf_filename]) / 1024:.1f} KB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3: Extract text from PDF\n",
        "import pdfplumber\n",
        "import pandas as pd\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extract text from all pages\"\"\"\n",
        "    pages_text = []\n",
        "    \n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        print(f\"üìÑ PDF has {len(pdf.pages)} pages\\n\")\n",
        "        \n",
        "        for i, page in enumerate(pdf.pages, 1):\n",
        "            text = page.extract_text()\n",
        "            if text:\n",
        "                pages_text.append({\n",
        "                    'page': i,\n",
        "                    'text': text\n",
        "                })\n",
        "                print(f\"   Page {i:3d}: {len(text):6d} characters\")\n",
        "    \n",
        "    return pages_text\n",
        "\n",
        "# Extract\n",
        "print(\"üîç Extracting text...\\n\")\n",
        "pages = extract_text_from_pdf(pdf_filename)\n",
        "print(f\"\\n‚úÖ Extracted {len(pages)} pages\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4: Find products with prices\n",
        "import re\n",
        "\n",
        "def find_products_with_prices(text, page_num):\n",
        "    \"\"\"Find products with prices in text\"\"\"\n",
        "    products = []\n",
        "    \n",
        "    # Price patterns for different currencies\n",
        "    patterns = [\n",
        "        r'¬£([\\d,]+(?:\\.\\d{2})?)',  # GBP: ¬£1,234.56\n",
        "        r'\\$([\\d,]+(?:\\.\\d{2})?)',  # USD: $1,234.56\n",
        "        r'‚Ç¨([\\d,]+(?:\\.\\d{2})?)',   # EUR: ‚Ç¨1,234.56\n",
        "        r'‚Ç™([\\d,]+(?:\\.\\d{2})?)',   # ILS: ‚Ç™1,234.56\n",
        "    ]\n",
        "    \n",
        "    currencies = ['GBP', 'USD', 'EUR', 'ILS']\n",
        "    \n",
        "    for pattern, currency in zip(patterns, currencies):\n",
        "        for match in re.finditer(pattern, text):\n",
        "            price_str = match.group(1).replace(',', '')\n",
        "            try:\n",
        "                price = float(price_str)\n",
        "            except:\n",
        "                continue\n",
        "            \n",
        "            if price < 5:  # Skip too small prices (likely page numbers)\n",
        "                continue\n",
        "            \n",
        "            # Get context around price (300 chars before and after)\n",
        "            start = max(0, match.start() - 300)\n",
        "            end = min(len(text), match.end() + 300)\n",
        "            context = text[start:end]\n",
        "            \n",
        "            # Try to find product name (lines before price)\n",
        "            before = context[:match.start()-start]\n",
        "            lines = [l.strip() for l in before.split('\\n') if l.strip()]\n",
        "            \n",
        "            product_name = ''\n",
        "            for line in reversed(lines):\n",
        "                if len(line) > 10 and not re.match(r'^[¬£$‚Ç¨‚Ç™\\d,\\.\\s]+$', line):\n",
        "                    product_name = line\n",
        "                    break\n",
        "            \n",
        "            if product_name and price > 0:\n",
        "                products.append({\n",
        "                    'page': page_num,\n",
        "                    'name': product_name[:300],\n",
        "                    'price': price,\n",
        "                    'currency': currency,\n",
        "                    'context': context[:500]\n",
        "                })\n",
        "    \n",
        "    return products\n",
        "\n",
        "# Search all pages\n",
        "print(\"üîç Searching for products with prices...\\n\")\n",
        "all_products = []\n",
        "\n",
        "for page_data in pages:\n",
        "    products = find_products_with_prices(page_data['text'], page_data['page'])\n",
        "    all_products.extend(products)\n",
        "    if products:\n",
        "        print(f\"   Page {page_data['page']:3d}: {len(products)} products found\")\n",
        "\n",
        "print(f\"\\n‚úÖ Found {len(all_products)} potential products\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 5: Clean and organize data\n",
        "def is_valid_product(name):\n",
        "    \"\"\"Filter out non-products\"\"\"\n",
        "    name_lower = name.lower()\n",
        "    \n",
        "    # Exclude keywords\n",
        "    exclude = [\n",
        "        'subscription', 'magazine', 'event', 'training',\n",
        "        'course', 'seminar', 'conference', 'membership',\n",
        "        'advertisement', 'sponsored', 'page', 'issue',\n",
        "        'editorial', 'contents', 'classified'\n",
        "    ]\n",
        "    \n",
        "    return not any(kw in name_lower for kw in exclude)\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(all_products)\n",
        "\n",
        "if not df.empty:\n",
        "    print(\"üßπ Cleaning data...\\n\")\n",
        "    \n",
        "    initial_count = len(df)\n",
        "    \n",
        "    # Remove duplicates\n",
        "    df = df.drop_duplicates(subset=['name', 'price', 'currency'])\n",
        "    print(f\"   Removed {initial_count - len(df)} duplicates\")\n",
        "    \n",
        "    # Filter by name length\n",
        "    df = df[df['name'].str.len() > 15]\n",
        "    \n",
        "    # Filter by price (reasonable range)\n",
        "    df = df[df['price'] > 10]\n",
        "    df = df[df['price'] < 100000]\n",
        "    \n",
        "    # Filter valid products\n",
        "    df = df[df['name'].apply(is_valid_product)]\n",
        "    \n",
        "    # Sort by price\n",
        "    df = df.sort_values('price', ascending=False)\n",
        "    df = df.reset_index(drop=True)\n",
        "    \n",
        "    print(f\"   Final products: {len(df)}\")\n",
        "    print(f\"\\n‚úÖ Data cleaned and ready!\")\n",
        "else:\n",
        "    print(\"‚ùå No products found in PDF\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 6: View summary and preview\n",
        "if not df.empty:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"üìä SUMMARY\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Total products: {len(df)}\")\n",
        "    print(f\"\\nBy currency:\")\n",
        "    for curr in df['currency'].unique():\n",
        "        count = len(df[df['currency'] == curr])\n",
        "        total = df[df['currency'] == curr]['price'].sum()\n",
        "        avg = df[df['currency'] == curr]['price'].mean()\n",
        "        print(f\"   {curr}: {count} products, Total: {curr} {total:,.2f}, Avg: {curr} {avg:,.2f}\")\n",
        "    \n",
        "    print(f\"\\nPrice range: {df['price'].min():.2f} - {df['price'].max():.2f}\")\n",
        "    print(f\"Average price: {df['price'].mean():.2f}\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    print(\"\\nüîç Preview (top 10 most expensive):\\n\")\n",
        "    preview = df[['page', 'name', 'price', 'currency']].head(10)\n",
        "    print(preview.to_string(index=False))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 7: Export to CSV\n",
        "if not df.empty:\n",
        "    # Prepare export data\n",
        "    df_export = df[['page', 'name', 'price', 'currency']].copy()\n",
        "    \n",
        "    # Generate filename\n",
        "    import os\n",
        "    base_name = os.path.splitext(pdf_filename)[0]\n",
        "    csv_filename = f\"{base_name}_products.csv\"\n",
        "    \n",
        "    # Save CSV\n",
        "    df_export.to_csv(csv_filename, index=False, encoding='utf-8')\n",
        "    \n",
        "    print(f\"\\n‚úÖ Saved to: {csv_filename}\")\n",
        "    print(f\"   {len(df_export)} products exported\")\n",
        "    \n",
        "    # Download file\n",
        "    print(\"\\nüì• Downloading CSV...\")\n",
        "    files.download(csv_filename)\n",
        "    print(\"‚úÖ Download complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 8: Generate SQL for database\n",
        "if not df.empty:\n",
        "    sql_lines = [\n",
        "        \"-- Products extracted from PDF magazine\",\n",
        "        \"-- Run this in pgAdmin on database 'gogobe'\",\n",
        "        \"-- Or use: psql -U postgres -d gogobe -f thisfile.sql\\n\",\n",
        "        \"DO $$\",\n",
        "        \"DECLARE\",\n",
        "        \"    dental_id INTEGER;\",\n",
        "        \"    cat_id INTEGER;\",\n",
        "        \"    supp_id INTEGER;\",\n",
        "        \"    pid BIGINT;\",\n",
        "        \"BEGIN\",\n",
        "        \"    -- Get vertical ID\",\n",
        "        \"    SELECT id INTO dental_id FROM verticals WHERE slug = 'dental';\",\n",
        "        \"    \",\n",
        "        \"    -- Get category ID (using first available)\",\n",
        "        \"    SELECT id INTO cat_id FROM categories WHERE vertical_id = dental_id LIMIT 1;\",\n",
        "        \"    \",\n",
        "        \"    -- Create a generic supplier for magazine extracts\",\n",
        "        \"    INSERT INTO suppliers (name, slug, country)\",\n",
        "        \"    VALUES ('PDF Magazine Extract', 'pdf-magazine', 'UK')\",\n",
        "        \"    ON CONFLICT DO NOTHING;\",\n",
        "        \"    \",\n",
        "        \"    SELECT id INTO supp_id FROM suppliers WHERE slug = 'pdf-magazine';\",\n",
        "        \"    \\n\"\n",
        "    ]\n",
        "    \n",
        "    # Add each product\n",
        "    for idx, row in df.iterrows():\n",
        "        name = row['name'].replace(\"'\", \"''\")  # Escape quotes\n",
        "        price = row['price']\n",
        "        currency = row['currency']\n",
        "        page = row['page']\n",
        "        \n",
        "        sql_lines.append(f\"    -- Product {idx+1} (Page {page}): {name[:50]}...\")\n",
        "        sql_lines.append(f\"    INSERT INTO products (name, vertical_id, category_id, description)\")\n",
        "        sql_lines.append(f\"    VALUES (\")\n",
        "        sql_lines.append(f\"        '{name}',\")\n",
        "        sql_lines.append(f\"        dental_id,\")\n",
        "        sql_lines.append(f\"        cat_id,\")\n",
        "        sql_lines.append(f\"        'Extracted from {pdf_filename}, page {page}'\")\n",
        "        sql_lines.append(f\"    )\")\n",
        "        sql_lines.append(f\"    ON CONFLICT DO NOTHING\")\n",
        "        sql_lines.append(f\"    RETURNING id INTO pid;\")\n",
        "        sql_lines.append(f\"    \")\n",
        "        sql_lines.append(f\"    IF pid IS NOT NULL THEN\")\n",
        "        sql_lines.append(f\"        INSERT INTO prices (product_id, supplier_id, price, currency, scraped_at)\")\n",
        "        sql_lines.append(f\"        VALUES (pid, supp_id, {price}, '{currency}', NOW());\")\n",
        "        sql_lines.append(f\"        RAISE NOTICE '‚úÖ Product {idx+1}: {name[:40]}...';\")\n",
        "        sql_lines.append(f\"    END IF;\")\n",
        "        sql_lines.append(f\"    \")\n",
        "    \n",
        "    sql_lines.append(\"END $$;\")\n",
        "    sql_lines.append(\"\")\n",
        "    sql_lines.append(\"-- View results\")\n",
        "    sql_lines.append(\"SELECT p.name, pr.price, pr.currency, s.name as supplier\")\n",
        "    sql_lines.append(\"FROM products p\")\n",
        "    sql_lines.append(\"JOIN prices pr ON p.id = pr.product_id\")\n",
        "    sql_lines.append(\"JOIN suppliers s ON pr.supplier_id = s.id\")\n",
        "    sql_lines.append(\"WHERE p.description LIKE '%Extracted from%'\")\n",
        "    sql_lines.append(\"ORDER BY pr.price DESC;\")\n",
        "    \n",
        "    # Save SQL file\n",
        "    sql_filename = f\"{base_name}_products.sql\"\n",
        "    with open(sql_filename, 'w', encoding='utf-8') as f:\n",
        "        f.write('\\n'.join(sql_lines))\n",
        "    \n",
        "    print(f\"\\n‚úÖ SQL file created: {sql_filename}\")\n",
        "    print(f\"   {len(df)} INSERT statements generated\")\n",
        "    \n",
        "    # Download SQL\n",
        "    print(\"\\nüì• Downloading SQL...\")\n",
        "    files.download(sql_filename)\n",
        "    print(\"‚úÖ Download complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 9: Next Steps\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéâ PDF SCANNING COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nüì¶ Files downloaded:\")\n",
        "print(f\"   1. {csv_filename} - Spreadsheet format\")\n",
        "print(f\"   2. {sql_filename} - Database ready\")\n",
        "\n",
        "print(\"\\nüöÄ Next steps:\")\n",
        "print(\"\\n1Ô∏è‚É£  Open CSV in Excel/Google Sheets\")\n",
        "print(\"   - Review products\")\n",
        "print(\"   - Edit if needed\")\n",
        "print(\"   - Analyze data\")\n",
        "\n",
        "print(\"\\n2Ô∏è‚É£  Load into PostgreSQL database:\")\n",
        "print(\"   On your computer, run:\")\n",
        "print(f'   psql -U postgres -d gogobe -f \"{sql_filename}\"')\n",
        "\n",
        "print(\"\\n3Ô∏è‚É£  Or use pgAdmin:\")\n",
        "print(\"   - Open pgAdmin\")\n",
        "print(\"   - Select database 'gogobe'\")\n",
        "print(\"   - Tools ‚Üí Query Tool\")\n",
        "print(f\"   - Open {sql_filename}\")\n",
        "print(\"   - Press F5 to run\")\n",
        "\n",
        "print(\"\\nüìä Statistics:\")\n",
        "if not df.empty:\n",
        "    print(f\"   Products extracted: {len(df)}\")\n",
        "    print(f\"   Total value: {df['price'].sum():,.2f}\")\n",
        "    print(f\"   Pages scanned: {df['page'].nunique()}\")\n",
        "    print(f\"   Success rate: {len(df)/len(all_products)*100:.1f}%\")\n",
        "\n",
        "print(\"\\nüí° Tips for next time:\")\n",
        "print(\"   - Better PDFs = better results\")\n",
        "print(\"   - Clear formatting helps\")\n",
        "print(\"   - Review and clean data manually\")\n",
        "print(\"   - Build product categories\")\n",
        "\n",
        "print(\"\\nüîÑ Want to scan another PDF?\")\n",
        "print(\"   Just run all cells again!\")\n",
        "print(\"=\"*60)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
