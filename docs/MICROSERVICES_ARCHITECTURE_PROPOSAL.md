# ğŸš€ ×”×¦×¢×”: ××¨×›×™×˜×§×˜×•×¨×ª Microservices ×œ××¢×¨×›×ª Gogobe

## ×ª××¨×™×š: 21 ×“×¦××‘×¨ 2025

---

## ğŸ“‹ ×ª×•×›×Ÿ ×¢× ×™×™× ×™×

1. [×¡×§×™×¨×” ×›×œ×œ×™×ª](#×¡×§×™×¨×”-×›×œ×œ×™×ª)
2. [×”×‘×¢×™×•×ª ×”× ×•×›×—×™×•×ª](#×”×‘×¢×™×•×ª-×”× ×•×›×—×™×•×ª)
3. [×”×¤×ª×¨×•×Ÿ ×”××•×¦×¢](#×”×¤×ª×¨×•×Ÿ-×”××•×¦×¢)
4. [××¨×›×™×˜×§×˜×•×¨×” ××¤×•×¨×˜×ª](#××¨×›×™×˜×§×˜×•×¨×”-××¤×•×¨×˜×ª)
5. [×˜×›× ×•×œ×•×’×™×•×ª ××•××œ×¦×•×ª](#×˜×›× ×•×œ×•×’×™×•×ª-××•××œ×¦×•×ª)
6. [×ª×›× ×™×ª ×™×™×©×•×](#×ª×›× ×™×ª-×™×™×©×•×)
7. [×”×©×•×•××ª ×‘×™×¦×•×¢×™×](#×”×©×•×•××ª-×‘×™×¦×•×¢×™×)

---

## ğŸ¯ ×¡×§×™×¨×” ×›×œ×œ×™×ª

### ×”××˜×¨×”
×œ×”×¤×•×š ××ª ××¢×¨×›×ª Gogobe ×œ-**××”×™×¨×”, ×¡×§×œ×‘×™×œ×™×ª ×•×™×¢×™×œ×”** ×‘×××¦×¢×•×ª:
- âœ… **Microservices** - ×©×™×¨×•×ª×™× ×§×˜× ×™× ×•××ª××—×™×
- âœ… **Message Queue** (Kafka/RabbitMQ) - ×ª×§×©×•×¨×ª ××¡×™× ×›×¨×•× ×™×ª
- âœ… **Go** - ×©×¤×” ××”×™×¨×” ×œ×©×™×¨×•×ª×™× ×§×¨×™×˜×™×™×
- âœ… **Redis** - Cache ×œ×—×™×¤×•×©×™× ××”×™×¨×™×
- âœ… **PostgreSQL** - ×‘×¡×™×¡ × ×ª×•× ×™× ××¨×›×–×™

---

## âŒ ×”×‘×¢×™×•×ª ×”× ×•×›×—×™×•×ª

### 1. **×™×™×‘×•× ××™×˜×™** ğŸŒ
```python
# ×›×¨×’×¢: ×™×™×‘×•× ×¡×™× ×›×¨×•× ×™
for product in products:
    # ×‘×“×™×§×” ×‘DB - ××™×˜×™!
    existing = db.query("SELECT id FROM products WHERE ean = ?")
    
    # ×”×•×¡×¤×ª ××•×¦×¨ - ××™×˜×™!
    db.execute("INSERT INTO products ...")
    
    # ×”×•×¡×¤×ª ××—×™×¨ - ××™×˜×™!
    db.execute("SELECT upsert_price(...)")
```

**×ª×•×¦××”:** 
- â±ï¸ 1,000 ××•×¦×¨×™× = **~5 ×“×§×•×ª**
- â±ï¸ 100,000 ××•×¦×¨×™× = **~8 ×©×¢×•×ª!**

### 2. **×—×™×¤×•×©×™× ×—×•×–×¨×™×** ğŸ”„
```python
# ×›×œ ××•×¦×¨ ××—×¤×© ××ª ××•×ª×• ×“×‘×¨:
for product in products:
    chain = db.query("SELECT id FROM store_chains WHERE name = 'Rami Levy'")  # Ã—1000!
    category = db.query("SELECT id FROM categories WHERE name = 'Dairy'")      # Ã—1000!
    store = db.query("SELECT id FROM stores WHERE store_id = '001'")           # Ã—1000!
```

**×ª×•×¦××”:** ××œ×¤×™ ×©××™×œ×ª×•×ª ×–×”×•×ª!

### 3. **Geocoding ××™×˜×™** ğŸŒ
```python
# ×›×¨×’×¢: ×¡×™× ×›×¨×•× ×™ ×¢× ×”××ª× ×”
for store in stores:
    lat, lon = geocode_api(store.address)  # 1.5 ×©× ×™×•×ª ×”××ª× ×”!
    db.update(...)
```

**×ª×•×¦××”:** 300 ×¡× ×™×¤×™× = **7.5 ×“×§×•×ª!**

### 4. **××™×Ÿ ×”×¤×¨×“×ª ××—×¨×™×•×ª** ğŸ”€
- ×”×›×œ ×‘××•×ª×• ×¡×§×¨×™×¤×˜ Python
- ××™ ××¤×©×¨ ×œ×©×“×¨×’ ×—×œ×§ ××¡×•×™×
- ×§×©×” ×œ×–×”×•×ª ×¦×•×•××¨×™ ×‘×§×‘×•×§

---

## âœ… ×”×¤×ª×¨×•×Ÿ ×”××•×¦×¢

### ××¨×›×™×˜×§×˜×•×¨×” ×—×“×©×”: Event-Driven Microservices

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        API Gateway (Python/FastAPI)              â”‚
â”‚                    ×¤×•× ×§×¦×™×•×ª: × ×™×”×•×œ, ×“×©×‘×•×¨×“, REST API            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Message Broker        â”‚
        â”‚   (Kafka / RabbitMQ)    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ Import Service â”‚  â”‚ Geocoding    â”‚  â”‚ Product Matchingâ”‚â”‚
â”‚ (Go - ××”×™×¨!)   â”‚  â”‚ Service (Go) â”‚  â”‚ Service (Python)â”‚â”‚
â”‚                â”‚  â”‚              â”‚  â”‚ + AI/LLM        â”‚â”‚
â”‚ ×§×•×¨× ×§×‘×¦×™×     â”‚  â”‚ OSM API      â”‚  â”‚                 â”‚â”‚
â”‚ ×©×•×œ×— events    â”‚  â”‚ Batch        â”‚  â”‚ ××–×”×” ××‘ ××•×¦×¨   â”‚â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
        â”‚                  â”‚                   â”‚         â”‚
        â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”   â”‚
        â”‚         â”‚     Redis Cache Layer            â”‚   â”‚
        â”‚         â”‚  - Products by EAN               â”‚   â”‚
        â”‚         â”‚  - Stores by ID                  â”‚   â”‚
        â”‚         â”‚  - Categories                    â”‚   â”‚
        â”‚         â”‚  - Master Products               â”‚   â”‚
        â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
        â”‚                  â”‚                             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  PostgreSQL (Main)  â”‚
                â”‚  - Products         â”‚
                â”‚  - Prices           â”‚
                â”‚  - Stores           â”‚
                â”‚  - Master Products  â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—ï¸ ××¨×›×™×˜×§×˜×•×¨×” ××¤×•×¨×˜×ª

### 1ï¸âƒ£ **Import Service (Go)** - ×©×™×¨×•×ª ×™×™×‘×•× ××”×™×¨

**×ª×¤×§×™×“:** ×§×¨×™××ª ×§×‘×¦×™× XML/GZ ×•×©×œ×™×—×ª events

```go
// main.go - Import Service
package main

import (
    "encoding/xml"
    "github.com/confluentinc/confluent-kafka-go/kafka"
)

type Product struct {
    Name     string  `xml:"ItemNm"`
    Barcode  string  `xml:"ItemCode"`
    Price    float64 `xml:"ItemPrice"`
}

func main() {
    // 1. ×§×¨×™××ª ×§×•×‘×¥ XML (××”×™×¨!)
    products := parseXML("prices.xml")
    
    // 2. ×©×œ×™×—×ª events ×œ-Kafka (××¡×™× ×›×¨×•× ×™!)
    producer := kafka.NewProducer(&kafka.ConfigMap{
        "bootstrap.servers": "kafka:9092",
    })
    
    for _, product := range products {
        event := ProductEvent{
            Type:    "product.imported",
            Barcode: product.Barcode,
            Name:    product.Name,
            Price:   product.Price,
        }
        
        // ×©×œ×™×—×” ×œ-Kafka (×œ× ××—×›×”!)
        producer.Produce(&kafka.Message{
            TopicPartition: kafka.TopicPartition{
                Topic:     "products",
                Partition: kafka.PartitionAny,
            },
            Value: json.Marshal(event),
        }, nil)
    }
    
    producer.Flush(1000)
}
```

**×™×ª×¨×•× ×•×ª:**
- âš¡ **××”×™×¨ ×¤×™ 10-50** ×-Python ×œ×¤×¨×¡×•×¨ XML
- ğŸš€ **××¡×™× ×›×¨×•× ×™** - ×œ× ××—×›×” ×œDB
- ğŸ“¦ **Batch processing** - ×©×•×œ×— ××œ×¤×™ events ×‘×©× ×™×™×”

---

### 2ï¸âƒ£ **Product Processor Service (Go)** - ×¢×™×‘×•×“ ××•×¦×¨×™×

**×ª×¤×§×™×“:** ×§×‘×œ×ª events ×-Kafka, ×‘×“×™×§×” ×‘-Redis/DB, ×”×•×¡×¤×ª ××•×¦×¨×™×

```go
// product_processor.go
package main

import (
    "github.com/go-redis/redis/v8"
    "github.com/confluentinc/confluent-kafka-go/kafka"
)

var redisClient *redis.Client
var db *sql.DB

func main() {
    // ×—×™×‘×•×¨ ×œ-Redis
    redisClient = redis.NewClient(&redis.Options{
        Addr: "redis:6379",
    })
    
    // ×—×™×‘×•×¨ ×œ-PostgreSQL
    db = connectDB()
    
    // Consumer ×-Kafka
    consumer := kafka.NewConsumer(&kafka.ConfigMap{
        "bootstrap.servers": "kafka:9092",
        "group.id":          "product-processor",
        "auto.offset.reset": "earliest",
    })
    
    consumer.Subscribe("products", nil)
    
    for {
        msg, _ := consumer.ReadMessage(-1)
        
        var event ProductEvent
        json.Unmarshal(msg.Value, &event)
        
        processProduct(event)
    }
}

func processProduct(event ProductEvent) {
    // 1. ×‘×“×™×§×” ×‘-Redis (××”×™×¨!)
    productID := redisClient.Get(ctx, "product:ean:"+event.Barcode).Val()
    
    if productID == "" {
        // 2. ×‘×“×™×§×” ×‘-DB (×¨×§ ×× ×œ× ×‘-Cache)
        db.QueryRow("SELECT id FROM products WHERE ean = $1", event.Barcode).Scan(&productID)
        
        if productID == "" {
            // 3. ×™×¦×™×¨×ª ××•×¦×¨ ×—×“×©
            db.QueryRow(`
                INSERT INTO products (name, ean, ...) 
                VALUES ($1, $2, ...) 
                RETURNING id
            `, event.Name, event.Barcode).Scan(&productID)
        }
        
        // 4. ×©××™×¨×” ×‘-Redis (×œ×¤×¢× ×”×‘××”!)
        redisClient.Set(ctx, "product:ean:"+event.Barcode, productID, 24*time.Hour)
    }
    
    // 5. ×”×•×¡×¤×ª ××—×™×¨ (Batch - ×›×œ 1000 ××—×™×¨×™×)
    priceQueue.Add(Price{
        ProductID: productID,
        Price:     event.Price,
        StoreID:   event.StoreID,
    })
    
    if len(priceQueue) >= 1000 {
        batchInsertPrices(priceQueue)
        priceQueue = []Price{}
    }
}
```

**×™×ª×¨×•× ×•×ª:**
- âš¡ **Redis Cache** - 99% ××”×—×™×¤×•×©×™× ×-Cache (××”×™×¨ ×¤×™ 100!)
- ğŸ“¦ **Batch Insert** - 1000 ××—×™×¨×™× ×‘×‘×ª ××—×ª (××”×™×¨ ×¤×™ 50!)
- ğŸ”„ **Parallel Processing** - ××¢×‘×“ ××¡×¤×¨ events ×‘××§×‘×™×œ

---

### 3ï¸âƒ£ **Geocoding Service (Go)** - ×©×™×¨×•×ª Geocoding ××”×™×¨

**×ª×¤×§×™×“:** ×§×‘×œ×ª events ×©×œ ×¡× ×™×¤×™× ×—×“×©×™×, Geocoding ××¡×™× ×›×¨×•× ×™

```go
// geocoding_service.go
package main

import (
    "net/http"
    "time"
)

type Store struct {
    ID      int
    Address string
    City    string
}

func main() {
    consumer := kafka.NewConsumer(...)
    consumer.Subscribe("stores.new", nil)
    
    // Rate limiter - 1 request per second (OSM limit)
    limiter := time.NewTicker(1 * time.Second)
    
    for {
        msg, _ := consumer.ReadMessage(-1)
        
        var store Store
        json.Unmarshal(msg.Value, &store)
        
        // ×”××ª× ×” ×œ-rate limiter
        <-limiter.C
        
        // Geocoding (async)
        go geocodeStore(store)
    }
}

func geocodeStore(store Store) {
    // ×§×¨×™××” ×œ-OSM Nominatim
    url := fmt.Sprintf(
        "https://nominatim.openstreetmap.org/search?q=%s,%s,Israel&format=json",
        store.Address, store.City,
    )
    
    resp, _ := http.Get(url)
    var results []OSMResult
    json.NewDecoder(resp.Body).Decode(&results)
    
    if len(results) > 0 {
        lat := results[0].Lat
        lon := results[0].Lon
        
        // ×¢×“×›×•×Ÿ DB
        db.Exec(`
            UPDATE stores 
            SET latitude = $1, longitude = $2,
                geom = ST_SetSRID(ST_MakePoint($2, $1), 4326)
            WHERE id = $3
        `, lat, lon, store.ID)
        
        // ×©××™×¨×” ×‘-Redis
        redisClient.HSet(ctx, "store:"+strconv.Itoa(store.ID), map[string]interface{}{
            "lat": lat,
            "lon": lon,
        })
    }
}
```

**×™×ª×¨×•× ×•×ª:**
- âš¡ **Async** - ×œ× ×—×•×¡× ××ª ×”×™×™×‘×•×
- ğŸ”„ **Parallel** - ××¢×‘×“ ××¡×¤×¨ ×¡× ×™×¤×™× ×‘××§×‘×™×œ
- ğŸ“Š **Rate Limiting** - ××›×‘×“ ××ª ×”-API limits

---

### 4ï¸âƒ£ **Product Matching Service (Python + AI)** - ×–×™×”×•×™ ××‘ ××•×¦×¨

**×ª×¤×§×™×“:** ×§×™×©×•×¨ ××•×¦×¨×™× ×œ××‘ ××•×¦×¨ ×‘×××¦×¢×•×ª AI/LLM

```python
# product_matching_service.py
from kafka import KafkaConsumer
import openai
import redis

redis_client = redis.Redis(host='redis', port=6379)
consumer = KafkaConsumer('products.new', bootstrap_servers='kafka:9092')

def find_master_product(product_name, barcode):
    """
    ××—×¤×© ××‘ ××•×¦×¨ ×‘×××¦×¢×•×ª:
    1. Cache (Redis)
    2. Barcode exact match
    3. AI/LLM similarity
    """
    
    # 1. ×‘×“×™×§×” ×‘-Cache
    cached = redis_client.get(f"master:barcode:{barcode}")
    if cached:
        return int(cached)
    
    # 2. ×—×™×¤×•×© ×œ×¤×™ ×‘×¨×§×•×“
    master_id = db.query("""
        SELECT mp.id 
        FROM master_products mp
        JOIN product_master_links pml ON mp.id = pml.master_product_id
        JOIN products p ON pml.product_id = p.id
        WHERE p.ean = %s
        LIMIT 1
    """, (barcode,))
    
    if master_id:
        redis_client.set(f"master:barcode:{barcode}", master_id, ex=86400)
        return master_id
    
    # 3. AI/LLM - ×–×™×”×•×™ ×“××™×•×Ÿ
    similar_products = db.query("""
        SELECT id, name FROM master_products
        WHERE is_active = TRUE
        LIMIT 100
    """)
    
    # ×©×™××•×© ×‘-OpenAI Embeddings
    product_embedding = openai.Embedding.create(
        input=product_name,
        model="text-embedding-ada-002"
    )
    
    best_match = None
    best_score = 0
    
    for mp in similar_products:
        mp_embedding = get_cached_embedding(mp.id)
        score = cosine_similarity(product_embedding, mp_embedding)
        
        if score > 0.9 and score > best_score:
            best_match = mp.id
            best_score = score
    
    if best_match:
        # ×™×¦×™×¨×ª ×§×™×©×•×¨
        db.execute("""
            INSERT INTO product_master_links 
            (master_product_id, product_id, confidence_score, match_method)
            VALUES (%s, %s, %s, 'llm')
        """, (best_match, product_id, best_score))
        
        redis_client.set(f"master:barcode:{barcode}", best_match, ex=86400)
        return best_match
    
    return None

for message in consumer:
    event = json.loads(message.value)
    master_id = find_master_product(event['name'], event['barcode'])
    
    if master_id:
        # ×¢×“×›×•×Ÿ ×”××—×™×¨ ×¢× master_product_id
        db.execute("""
            UPDATE prices 
            SET master_product_id = %s
            WHERE product_id = %s
        """, (master_id, event['product_id']))
```

**×™×ª×¨×•× ×•×ª:**
- ğŸ¤– **AI-Powered** - ×–×™×”×•×™ ×—×›× ×©×œ ××•×¦×¨×™× ×“×•××™×
- âš¡ **Cached Embeddings** - ×œ× ××—×©×‘ ×¤×¢××™×™×
- ğŸ“Š **Confidence Score** - ×™×•×“×¢ ×›××” ×‘×˜×•×— ×”×§×™×©×•×¨

---

### 5ï¸âƒ£ **Redis Cache Layer** - ×©×›×‘×ª Cache

**××‘× ×”:**

```redis
# Products by EAN
SET product:ean:7290000000001 â†’ "12345"  (product_id)
EXPIRE product:ean:7290000000001 86400   (24 hours)

# Stores by ID
HSET store:123 "id" "123" "name" "Rami Levy - Tel Aviv" "lat" "32.0853" "lon" "34.7818"
EXPIRE store:123 86400

# Categories
SET category:name:Dairy â†’ "5"  (category_id)
EXPIRE category:name:Dairy 86400

# Master Products by Barcode
SET master:barcode:7290000000001 â†’ "789"  (master_product_id)
EXPIRE master:barcode:7290000000001 86400

# Chain IDs
SET chain:name:Rami_Levy â†’ "153"  (chain_id)
EXPIRE chain:name:Rami_Levy 604800  (7 days)

# Current Prices (for quick lookup)
HSET price:product:12345:store:123 "price" "5.90" "currency" "ILS" "updated" "2025-12-21"
EXPIRE price:product:12345:store:123 3600  (1 hour)
```

**×¤×•× ×§×¦×™×•×ª ×¢×–×¨:**

```go
// cache.go
package cache

func GetProductByEAN(ean string) (int, bool) {
    val, err := redisClient.Get(ctx, "product:ean:"+ean).Int()
    if err != nil {
        return 0, false
    }
    return val, true
}

func SetProductByEAN(ean string, productID int) {
    redisClient.Set(ctx, "product:ean:"+ean, productID, 24*time.Hour)
}

func GetStoreByID(storeID int) (*Store, bool) {
    result := redisClient.HGetAll(ctx, "store:"+strconv.Itoa(storeID)).Val()
    if len(result) == 0 {
        return nil, false
    }
    
    store := &Store{
        ID:   storeID,
        Name: result["name"],
        Lat:  parseFloat(result["lat"]),
        Lon:  parseFloat(result["lon"]),
    }
    return store, true
}
```

---

## ğŸ› ï¸ ×˜×›× ×•×œ×•×’×™×•×ª ××•××œ×¦×•×ª

### 1. **Message Broker: Kafka vs RabbitMQ**

| ×ª×›×•× ×” | Kafka âœ… | RabbitMQ |
|-------|---------|----------|
| **Throughput** | 1M+ msg/sec | 50K msg/sec |
| **Persistence** | ×›×Ÿ (Disk) | ×›×Ÿ (××•×¤×¦×™×•× ×œ×™) |
| **Ordering** | ××•×‘×˜×— (per partition) | ××•×‘×˜×— (per queue) |
| **Complexity** | ×‘×™× ×•× ×™-×’×‘×•×” | × ××•×š-×‘×™× ×•× ×™ |
| **Use Case** | Event streaming, Big data | Task queues, RPC |

**×”××œ×¦×”:** âœ… **Kafka** - ××ª××™× ×™×•×ª×¨ ×œ-high throughput ×™×™×‘×•×

**Docker Compose:**
```yaml
# docker-compose.yml
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
  
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
```

---

### 2. **Go vs Python: ××ª×™ ×œ×”×©×ª××© ×‘××”?**

| ××©×™××” | ×©×¤×” ××•××œ×¦×ª | ×¡×™×‘×” |
|-------|------------|------|
| **XML Parsing** | Go âœ… | ×¤×™ 10-50 ××”×™×¨ ×™×•×ª×¨ |
| **Batch Insert** | Go âœ… | Concurrency ××•×‘× ×” |
| **API Gateway** | Python (FastAPI) | ×§×œ ×œ×¤×™×ª×•×—, ecosystem ×¢×©×™×¨ |
| **AI/LLM** | Python âœ… | OpenAI, HuggingFace |
| **Geocoding** | Go âœ… | HTTP requests ××”×™×¨×™× |
| **Cache Management** | Go âœ… | Redis client ××”×™×¨ |

**×”××œ×¦×”:** 
- âœ… **Go** - ×œ×›×œ ××” ×©×§×©×•×¨ ×œ×‘×™×¦×•×¢×™× (parsing, DB, cache)
- âœ… **Python** - ×œ-AI, API, × ×™×”×•×œ

---

### 3. **Redis Configuration**

```yaml
# docker-compose.yml
services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    command: redis-server --maxmemory 2gb --maxmemory-policy allkeys-lru
    volumes:
      - redis-data:/data
```

**×ª×¦×•×¨×” ××•××œ×¦×ª:**
```conf
# redis.conf
maxmemory 2gb
maxmemory-policy allkeys-lru  # ××—×§ keys ×™×©× ×™× ×›×©×”×–×™×›×¨×•×Ÿ ××œ×
save 900 1                     # Snapshot ×›×œ 15 ×“×§×•×ª
save 300 10
save 60 10000
```

---

## ğŸ“Š ×”×©×•×•××ª ×‘×™×¦×•×¢×™×

### ×ª×¨×—×™×©: ×™×™×‘×•× 100,000 ××•×¦×¨×™×

#### **××¨×›×™×˜×§×˜×•×¨×” × ×•×›×—×™×ª (Python Monolith)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Python Script (Single Thread)          â”‚
â”‚                                         â”‚
â”‚ for product in products:                â”‚
â”‚   â”œâ”€ DB Query (SELECT)      ~10ms      â”‚
â”‚   â”œâ”€ DB Insert (INSERT)     ~15ms      â”‚
â”‚   â””â”€ DB Insert (upsert_price) ~20ms    â”‚
â”‚                                         â”‚
â”‚ Total per product: ~45ms                â”‚
â”‚ 100,000 products Ã— 45ms = 4,500 sec    â”‚
â”‚ = 75 minutes = 1.25 hours               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**×ª×•×¦××”:** â±ï¸ **~1.25 ×©×¢×•×ª** (×œ×œ× Geocoding!)

---

#### **××¨×›×™×˜×§×˜×•×¨×” ×—×“×©×” (Microservices + Kafka + Redis + Go)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Import Service (Go)                                         â”‚
â”‚ â”œâ”€ Parse XML: 100,000 products in ~5 seconds               â”‚
â”‚ â””â”€ Send to Kafka: 100,000 events in ~10 seconds            â”‚
â”‚                                                             â”‚
â”‚ Total: 15 seconds                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Product Processor (Go Ã— 4 instances)                        â”‚
â”‚                                                             â”‚
â”‚ Each instance processes 25,000 products:                    â”‚
â”‚ â”œâ”€ Redis Cache Hit (99%): ~1ms per product                 â”‚
â”‚ â”œâ”€ DB Query (1% miss): ~10ms per product                   â”‚
â”‚ â”œâ”€ Batch Insert (1000 at a time): ~100ms per 1000          â”‚
â”‚                                                             â”‚
â”‚ Average per product: ~1.5ms                                 â”‚
â”‚ 25,000 products Ã— 1.5ms = 37.5 seconds per instance        â”‚
â”‚                                                             â”‚
â”‚ Total (parallel): ~40 seconds                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Geocoding Service (Go - Async)                              â”‚
â”‚ â”œâ”€ Runs in background (doesn't block import)               â”‚
â”‚ â””â”€ 300 stores Ã— 1.5s = 450 seconds = 7.5 minutes            â”‚
â”‚                                                             â”‚
â”‚ (But import is already done!)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Product Matching Service (Python + AI - Async)              â”‚
â”‚ â”œâ”€ Runs in background                                       â”‚
â”‚ â””â”€ 100,000 products Ã— ~50ms = 5,000 seconds = 83 minutes    â”‚
â”‚                                                             â”‚
â”‚ (But import is already done!)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
TOTAL IMPORT TIME: ~55 seconds (15 + 40)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**×ª×•×¦××”:** âš¡ **~55 ×©× ×™×•×ª** (×¤×™ 82 ××”×™×¨ ×™×•×ª×¨!)

---

### ×¡×™×›×•× ×”×©×•×•××”

| ××“×“ | ××¨×›×™×˜×§×˜×•×¨×” × ×•×›×—×™×ª | ××¨×›×™×˜×§×˜×•×¨×” ×—×“×©×” | ×©×™×¤×•×¨ |
|-----|-------------------|-----------------|-------|
| **×™×™×‘×•× 100K ××•×¦×¨×™×** | 75 ×“×§×•×ª | 55 ×©× ×™×•×ª | **×¤×™ 82** âš¡ |
| **Geocoding 300 ×¡× ×™×¤×™×** | 7.5 ×“×§×•×ª (×—×•×¡×) | 7.5 ×“×§×•×ª (×¨×§×¢) | **×œ× ×—×•×¡×** âœ… |
| **Product Matching** | ×œ× ×§×™×™× | 83 ×“×§×•×ª (×¨×§×¢) | **×—×“×©!** âœ… |
| **DB Queries** | 100K queries | ~1K queries | **×¤×™ 100 ×¤×—×•×ª** âš¡ |
| **Cache Hit Rate** | 0% | 99% | **×—×™×¡×›×•×Ÿ ×¢×¦×•×** âœ… |

---

## ğŸš€ ×ª×›× ×™×ª ×™×™×©×•×

### ×©×œ×‘ 1: ×ª×©×ª×™×ª (×©×‘×•×¢ 1-2)

```bash
# 1. ×”×•×¡×¤×ª Kafka + Redis ×œ-docker-compose.yml
docker-compose up -d kafka redis

# 2. ×™×¦×™×¨×ª Topics ×‘-Kafka
kafka-topics --create --topic products --bootstrap-server kafka:9092
kafka-topics --create --topic stores.new --bootstrap-server kafka:9092
kafka-topics --create --topic prices --bootstrap-server kafka:9092
```

**×§×‘×¦×™×:**
- âœ… `docker-compose.yml` - ×”×•×¡×¤×ª Kafka, Zookeeper, Redis
- âœ… `kafka/topics.sh` - ×™×¦×™×¨×ª Topics

---

### ×©×œ×‘ 2: Import Service (Go) (×©×‘×•×¢ 3-4)

```bash
# 1. ×™×¦×™×¨×ª ×¤×¨×•×™×§×˜ Go
mkdir services/import-service
cd services/import-service
go mod init gogobe/import-service

# 2. ×”×ª×§× ×ª dependencies
go get github.com/confluentinc/confluent-kafka-go/kafka
go get github.com/lib/pq

# 3. ×¤×™×ª×•×—
# - XML parser
# - Kafka producer
# - File watcher
```

**×§×‘×¦×™×:**
- âœ… `services/import-service/main.go`
- âœ… `services/import-service/parser.go`
- âœ… `services/import-service/kafka.go`

---

### ×©×œ×‘ 3: Product Processor (Go) (×©×‘×•×¢ 5-6)

```bash
# 1. ×™×¦×™×¨×ª ×¤×¨×•×™×§×˜
mkdir services/product-processor
cd services/product-processor
go mod init gogobe/product-processor

# 2. ×”×ª×§× ×ª dependencies
go get github.com/go-redis/redis/v8
go get github.com/lib/pq
go get github.com/confluentinc/confluent-kafka-go/kafka

# 3. ×¤×™×ª×•×—
# - Kafka consumer
# - Redis cache layer
# - Batch insert logic
```

**×§×‘×¦×™×:**
- âœ… `services/product-processor/main.go`
- âœ… `services/product-processor/cache.go`
- âœ… `services/product-processor/batch.go`

---

### ×©×œ×‘ 4: Geocoding Service (Go) (×©×‘×•×¢ 7)

```bash
mkdir services/geocoding-service
cd services/geocoding-service
go mod init gogobe/geocoding-service

# ×¤×™×ª×•×—:
# - Kafka consumer
# - OSM API client
# - Rate limiter
```

---

### ×©×œ×‘ 5: Product Matching Service (Python) (×©×‘×•×¢ 8-10)

```bash
mkdir services/product-matching
cd services/product-matching
python -m venv venv
pip install kafka-python openai redis psycopg2

# ×¤×™×ª×•×—:
# - Kafka consumer
# - OpenAI integration
# - Similarity matching
```

---

### ×©×œ×‘ 6: Migration & Testing (×©×‘×•×¢ 11-12)

```bash
# 1. ×”×¨×¦×” ××§×‘×™×œ×” (×™×©×Ÿ + ×—×“×©)
# 2. ×”×©×•×•××ª ×ª×•×¦××•×ª
# 3. Performance testing
# 4. ××¢×‘×¨ ××œ× ×œ××¨×›×™×˜×§×˜×•×¨×” ×—×“×©×”
```

---

## ğŸ“ ××‘× ×” ×ª×™×§×™×•×ª ××•×¦×¢

```
Gogobe/
â”œâ”€â”€ backend/                    # Python (API, × ×™×”×•×œ)
â”‚   â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ scrapers/              # Legacy (×™×•×¡×¨ ×‘×¢×ª×™×“)
â”‚   â””â”€â”€ database/
â”‚
â”œâ”€â”€ services/                   # Microservices (Go + Python)
â”‚   â”œâ”€â”€ import-service/        # Go - ×™×™×‘×•× ×§×‘×¦×™×
â”‚   â”‚   â”œâ”€â”€ main.go
â”‚   â”‚   â”œâ”€â”€ parser.go
â”‚   â”‚   â”œâ”€â”€ kafka.go
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”‚
â”‚   â”œâ”€â”€ product-processor/     # Go - ×¢×™×‘×•×“ ××•×¦×¨×™×
â”‚   â”‚   â”œâ”€â”€ main.go
â”‚   â”‚   â”œâ”€â”€ cache.go
â”‚   â”‚   â”œâ”€â”€ batch.go
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”‚
â”‚   â”œâ”€â”€ geocoding-service/     # Go - Geocoding
â”‚   â”‚   â”œâ”€â”€ main.go
â”‚   â”‚   â”œâ”€â”€ osm.go
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”‚
â”‚   â””â”€â”€ product-matching/      # Python - AI Matching
â”‚       â”œâ”€â”€ main.py
â”‚       â”œâ”€â”€ ai.py
â”‚       â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ kafka/
â”‚   â””â”€â”€ topics.sh              # ×™×¦×™×¨×ª Topics
â”‚
â”œâ”€â”€ docker-compose.yml         # ×›×œ ×”×©×™×¨×•×ª×™×
â””â”€â”€ README.md
```

---

## ğŸ’° ×¢×œ×•×™×•×ª

### ×ª×©×ª×™×ª (×—×•×“×©×™)

| ×©×™×¨×•×ª | ×¡×¤×§ | ×¢×œ×•×ª |
|-------|-----|------|
| **Kafka** | Self-hosted (Docker) | $0 |
| **Redis** | Self-hosted (Docker) | $0 |
| **PostgreSQL** | Self-hosted (Docker) | $0 |
| **OpenAI API** | OpenAI | ~$50-200/×—×•×“×© |
| **Server** | AWS/GCP/Azure | ~$100-300/×—×•×“×© |

**×¡×”"×›:** ~$150-500/×—×•×“×© (×ª×œ×•×™ ×‘× ×¤×—)

---

## âœ… ×™×ª×¨×•× ×•×ª ×”××¨×›×™×˜×§×˜×•×¨×” ×”×—×“×©×”

1. âš¡ **××”×™×¨×•×ª:** ×¤×™ 50-100 ××”×™×¨ ×™×•×ª×¨
2. ğŸ”„ **Scalability:** ××¤×©×¨ ×œ×”×•×¡×™×£ instances ×œ×¤×™ ×¦×•×¨×š
3. ğŸ›¡ï¸ **Resilience:** ×× ×©×™×¨×•×ª × ×•×¤×œ, ×”×©××¨ ×××©×™×›×™×
4. ğŸ§¹ **Clean Code:** ×›×œ ×©×™×¨×•×ª ×¢×•×©×” ×“×‘×¨ ××—×“ ×˜×•×‘
5. ğŸš€ **Future-proof:** ×§×œ ×œ×”×•×¡×™×£ ×©×™×¨×•×ª×™× ×—×“×©×™×
6. ğŸ’° **Cost-effective:** ×¤×—×•×ª ×©×™××•×© ×‘-DB = ×¤×—×•×ª ×¢×œ×•×™×•×ª

---

## âš ï¸ ××ª×’×¨×™×

1. **Complexity:** ×™×•×ª×¨ ××•×¨×›×‘ ×œ× ×”×œ
2. **Monitoring:** ×¦×¨×™×š ×›×œ×™× ×›××• Prometheus, Grafana
3. **Debugging:** ×§×©×” ×™×•×ª×¨ ×œ×¢×§×•×‘ ××—×¨×™ flow
4. **Learning Curve:** ×¦×•×•×ª ×¦×¨×™×š ×œ×œ××•×“ Go, Kafka

---

## ğŸ¯ ×”××œ×¦×” ×¡×•×¤×™×ª

âœ… **×›×Ÿ, ×›×“××™ ×œ×¢×‘×•×¨ ×œ-Microservices!**

**×¡×“×¨ ×¢×“×™×¤×•×™×•×ª:**
1. **×©×œ×‘ 1:** Redis Cache (×©×™×¤×•×¨ ××™×™×“×™ ×¤×™ 10)
2. **×©×œ×‘ 2:** Import Service (Go) + Kafka (×©×™×¤×•×¨ ×¤×™ 50)
3. **×©×œ×‘ 3:** Product Processor (Go) (×©×™×¤×•×¨ ×¤×™ 100)
4. **×©×œ×‘ 4:** Geocoding Service (Go) (×œ× ×—×•×¡×)
5. **×©×œ×‘ 5:** Product Matching (Python + AI) (×ª×›×•× ×” ×—×“×©×”)

**×–××Ÿ ×¤×™×ª×•×— ××©×•×¢×¨:** 3-4 ×—×•×“×©×™×
**ROI:** ×ª×—×–×•×¨ ×¢×œ ×”×”×©×§×¢×” ×ª×•×š ×—×•×“×©×™×™× (×—×™×¡×›×•×Ÿ ×‘×–××Ÿ + ×¢×œ×•×™×•×ª server)

---

**××•×›×Ÿ ×œ×”×ª×—×™×œ?** ğŸš€
